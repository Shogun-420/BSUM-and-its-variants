{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Acc_BSUM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVW_e8vdeF0x"
      },
      "outputs": [],
      "source": [
        "def Acc_BSUM_Dict_Learning(Y, dims, lamda, max_iter = 150, A_init = None, X_init = None):\n",
        "  D, N, K = dims\n",
        "  A = generateRandomDict(D, K) if A_init is None else np.copy(A_init)\n",
        "  X = rng.standard_normal(size = (K, N)) if X_init is None else np.copy(X_init)\n",
        "\n",
        "  objective_values = np.zeros(max_iter, dtype = np.float64)\n",
        "  recon_error = np.zeros(max_iter, dtype = np.float64)\n",
        "  # objective_values[0] = d(Y, A, X)\n",
        "  # recon_error[0] = cal_recon_error(Y, A, X)\n",
        "\n",
        "  A_prev = np.copy(A)\n",
        "  w = np.zeros_like(A_prev)\n",
        "  i = 0\n",
        "  theta = np.zeros(max_iter, dtype = np.float64)\n",
        "  clf = LassoLars(alpha = lamda / D, normalize = False)\n",
        "  while(i < max_iter):\n",
        "    theta[i] = 2 / (i + 2)\n",
        "    V_r = (1 - theta[i-1]) * A_prev + theta[i] * w\n",
        "    clf.fit(V_r, Y)\n",
        "    X = clf.coef_.T\n",
        "    # tau_x = linalg.svdvals(V_r)[0] ** 2\n",
        "    # X = S(X - V_r.T @ (V_r @ X - Y) / tau_x , lamda / tau_x)\n",
        "    tau_a = linalg.svdvals(X)[0] ** 2\n",
        "    A_cur = P(V_r - (V_r @ X - Y) @ X.T / (tau_a))\n",
        "    w = A_prev + (A_cur - A_prev) / theta[i]\n",
        "\n",
        "    objective_values[i] = d(Y, A_cur, X)\n",
        "    recon_error[i] = cal_recon_error(Y, A_cur, X)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  return A_cur, X, objective_values, recon_error"
      ]
    }
  ]
}