{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIBSUM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QybJ7OOGehpi"
      },
      "outputs": [],
      "source": [
        "def MIBSUM_Dict_Learning(Y, dims, lamda, max_iter = 150, A_init = None, X_init = None):\n",
        "  D, N, K = dims\n",
        "  A = generateRandomDict(D, K) if A_init is None else np.copy(A_init)\n",
        "  X = rng.standard_normal(size = (K, N)) if X_init is None else np.copy(X_init)\n",
        "\n",
        "  max_iter = max_iter * 2\n",
        "  objective_values = np.zeros(max_iter, dtype = np.float64)\n",
        "  recon_error = np.zeros(max_iter, dtype = np.float64)\n",
        "  # objective_values[0] = d(Y, A, X)\n",
        "  # recon_error[0] = cal_recon_error(Y, A, X)\n",
        "  # objective_values[1] = d(Y, A, X)\n",
        "  # recon_error[1] = cal_recon_error(Y, A, X)\n",
        "\n",
        "  i = 0\n",
        "  while(i < max_iter):\n",
        "\n",
        "    tau_x = linalg.svdvals(A)[0] ** 2\n",
        "    X_ = S(X - A.T @ (A @ X - Y) / tau_x , lamda / tau_x)\n",
        "\n",
        "    tau_a = linalg.svdvals(X)[0] ** 2\n",
        "    A_ = P(A - (A @ X - Y) @ X.T / (tau_a))\n",
        "\n",
        "    if d(Y, A, X_) < d(Y, A_, X):\n",
        "      X[:, :] = X_\n",
        "    else:\n",
        "      A[:, :] = A_\n",
        "\n",
        "    curr_objective_val = d(Y, A, X)\n",
        "    curr_recon_error = cal_recon_error(Y, A, X)\n",
        "\n",
        "    objective_values[i] = curr_objective_val\n",
        "    recon_error[i] = cal_recon_error(Y, A, X)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  return A, X, objective_values, recon_error"
      ]
    }
  ]
}